{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter_code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Nju4v5I_yfG_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import os\n",
        "import PIL\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4_xzu8UatgOP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "''' Load the facial keypoints data. \n",
        "    Return: training face images with corresponding key points. ''' \n",
        "def load_data():\n",
        "    # load & read data\n",
        "    fname = 'data/training.csv'\n",
        "    df = pd.read_csv(os.path.expanduser(fname))  \n",
        "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
        "\n",
        "    # drop missing values\n",
        "    df = df.dropna() \n",
        "\n",
        "    # normalize\n",
        "    X = np.vstack(df['Image'].values) / 255.  \n",
        "    X = X.astype(np.float32)\n",
        "    \n",
        "    # reshape (96, 96, 1)\n",
        "    X = X.reshape(-1, 96, 96, 1) \n",
        "\n",
        "    y = df[df.columns[:-1]].values\n",
        "\n",
        "    # normalize\n",
        "    y = (y - 48) / 48  \n",
        "\n",
        "    X, y = shuffle(X, y, random_state=42)  \n",
        "    y = y.astype(np.float32)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "''' This class builds a simple convolutional neural network. \n",
        "    Predicts facial keypoints, given an image of a face. '''\n",
        "class CNNModel:\n",
        "    def __init__(self, filename):\n",
        "        # load model if exists\n",
        "        # else, train new model\n",
        "        self.filename = filename\n",
        "        if os.path.exists(self.filename):\n",
        "            self.model = load_model(self.filename)\n",
        "        else:\n",
        "            self.build_model()\n",
        "    \n",
        "    ''' Constructs a new convolutional neural network, and\n",
        "        saves as a .h5 file. '''\n",
        "    def build_model(self): \n",
        "        self.model = Sequential()\n",
        "        self.model.add(Convolution2D(32, (5, 5), input_shape=(96,96,1), activation='relu'))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        self.model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.model.add(Dropout(0.1))\n",
        "\n",
        "        self.model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.model.add(Dropout(0.2))\n",
        "\n",
        "        self.model.add(Convolution2D(30, (3, 3), activation='relu'))\n",
        "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        self.model.add(Dropout(0.3))\n",
        "\n",
        "        self.model.add(Flatten())\n",
        "\n",
        "        self.model.add(Dense(64, activation='relu'))\n",
        "        self.model.add(Dense(128, activation='relu'))\n",
        "        self.model.add(Dense(256, activation='relu'))\n",
        "        self.model.add(Dense(64, activation='relu'))\n",
        "        self.model.add(Dense(30))\n",
        "\n",
        "        self.model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "        x_train, y_train = load_data()\n",
        "        self.model.fit(x_train, y_train, epochs=100, batch_size=200, verbose=1, validation_split=0.2)\n",
        "        \n",
        "        self.model.save(self.filename)\n",
        "\n",
        "    ''' Predict keypoints, given a face image. '''\n",
        "    def predict(self, face): \n",
        "        return self.model.predict(face)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VXdvsEQcyojk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cv2_imshow(a):\n",
        "  \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\"\"\"\n",
        "  a = a.clip(0, 255).astype('uint8')\n",
        "  # cv2 stores colors as BGR; convert to RGB\n",
        "  if a.ndim == 3:\n",
        "    if a.shape[2] == 4:\n",
        "      a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
        "    else:\n",
        "      a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "  display(PIL.Image.fromarray(a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3IBB1Fw0yoxi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "''' Constructs a filter, given an image. \n",
        "    You can overlay this filter on the eyes, mouth, forehead, or nose. '''\n",
        "class Filter: \n",
        "    def __init__(self, filepath):\n",
        "        # read in filter image given filepath\n",
        "        self.filter = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    def eyes_overlay(self, points, frame):\n",
        "        # resize the filter image w.r.t. points\n",
        "        f_width = int(points[7][0] - points[9][0])\n",
        "        f_height = int(points[10][1] - points[8][1])\n",
        "        f_resized = cv2.resize(self.filter, (f_width, f_height), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        # get transparent region (i.e. alpha > 0.7)\n",
        "        transparent_region = f_resized[:, :, 3] > 0.7 \n",
        "\n",
        "        # get boundaries (global coord.)\n",
        "        xmin, xmax, ymin, ymax = self.get_x_y_min_max(points[9], f_width, f_height)\n",
        "        frame[ymin:ymax, xmin:xmax, :][transparent_region] = f_resized[:, :, :3][transparent_region]\n",
        "\n",
        "    def mouth_overlay(self, points, frame):\n",
        "        # TODO: create overlay function for mouth with any image found online!\n",
        "        return None\n",
        "\n",
        "    def forehead_overlay(self, points, frame):\n",
        "        # TODO: create overlay for forehead images (i.e. dog ears or flower crowns!)\n",
        "        return None\n",
        "\n",
        "    def nose_overlay(self, points, frame, vertical_shift=0):\n",
        "        # resize the filter image w.r.t. points\n",
        "        f_width = 100\n",
        "        f_height = 50\n",
        "        f_resized = cv2.resize(self.filter, (f_width, f_height), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        # get transparent region (i.e. alpha > 0.7)\n",
        "        transparent_region = f_resized[:, :, 3] > 0.7 \n",
        "        \n",
        "        # get boundaries (global coord.)\n",
        "        xmin, xmax, ymin, ymax = self.get_x_y_min_max(points[10], f_width, f_height)\n",
        "        \n",
        "        # shift the filter to be on center with the nose\n",
        "        xmin -= f_width // 2\n",
        "        xmax -= f_width // 2\n",
        "        ymin += vertical_shift\n",
        "        ymax += vertical_shift\n",
        "        frame[ymin:ymax, xmin:xmax, :][transparent_region] = f_resized[:, :, :3][transparent_region]\n",
        "\n",
        "    ''' \n",
        "    Returns the global coordinates box of the filter with respect to a certain point\n",
        "    ''' \n",
        "    def get_x_y_min_max(self, boundary_point, filter_width, filter_height):\n",
        "        ymin = int(boundary_point[1])\n",
        "        ymax = ymin + filter_height\n",
        "        xmin = int(boundary_point[0])\n",
        "        xmax = xmin + filter_width\n",
        "        return xmin, xmax, ymin, ymax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GNlgsJ174dBL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the model built in the previous step\n",
        "my_model = CNNModel('my_model.h5')\n",
        "\n",
        "# TODO: Face cascade to detect faces\n",
        "face_cascade = ...\n",
        "\n",
        "# TODO: add more filters!\n",
        "moustache = Filter(os.path.join('filters', 'moustache.png'))\n",
        "\n",
        "# Grab the current paintWindow\n",
        "frame = cv2.imread(\"imagepath\") # TODO: change to image path\n",
        "frame = cv2.flip(frame, 1)\n",
        "frame2 = np.copy(frame)\n",
        "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# TODO: Detect faces\n",
        "faces = ...\n",
        "if len(faces) == 0:\n",
        "    cv2.putText(frame, \"Finding Face...\", (37, 37), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "    cv2.imshow('Selfie Filters', frame)\n",
        "\n",
        "for (x, y, w, h) in faces:\n",
        "    # Grab the face\n",
        "    gray_face = gray[y:y+h, x:x+w]\n",
        "    color_face = frame[y:y+h, x:x+w]\n",
        "\n",
        "    # Normalize to match the input format of the model - Range of pixel to [0, 1]\n",
        "    gray_normalized = gray_face / 255\n",
        "\n",
        "    # Resize it to 96x96 to match the input format of the model\n",
        "    original_shape = gray_face.shape\n",
        "    face_resized = cv2.resize(gray_normalized, (96, 96), interpolation = cv2.INTER_AREA)\n",
        "    face_resized_copy = face_resized.copy()\n",
        "    face_resized = face_resized.reshape(1, 96, 96, 1)\n",
        "\n",
        "    # Predicting the keypoints using the model\n",
        "    keypoints = my_model.predict(face_resized)\n",
        "\n",
        "    # De-Normalize the keypoints values\n",
        "    keypoints = keypoints * 48 + 48\n",
        "\n",
        "    # Map the Keypoints back to the original image\n",
        "    face_resized_color = cv2.resize(color_face, (96, 96), interpolation = cv2.INTER_AREA)\n",
        "    face_resized_color2 = np.copy(face_resized_color)\n",
        "\n",
        "    x_scale = original_shape[1] / 96\n",
        "    y_scale = original_shape[0] / 96\n",
        "\n",
        "    # Pair them together\n",
        "    points = []\n",
        "    for i, co in enumerate(keypoints[0][0::2]):\n",
        "        points.append((co, keypoints[0][1::2][i]))\n",
        "\n",
        "    # Transform points to global coordinates\n",
        "    for i in range(len(points)):\n",
        "        points[i] *= np.array([x_scale, y_scale])\n",
        "        points[i] += np.array([x, y])\n",
        "\n",
        "    # TODO: Add more FILTERS to the frame\n",
        "    moustache.nose_overlay(points, frame, -5)\n",
        "\n",
        "    # Add KEYPOINTS to the frame2\n",
        "    for keypoint in points:\n",
        "        (px, py) = np.array(keypoint, dtype=np.int)\n",
        "        cv2.circle(frame2, (px, py), 1, (0,255,0), 1)\n",
        "\n",
        "    # Show the frame and the frame2\n",
        "    cv2_imshow(frame)\n",
        "    cv2_imshow(frame2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYxGwmC58cPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}